{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dhivyaindhu/Skill_upgrade-projects-task3/blob/main/Untitled60.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLMCX9kn6dZr",
        "outputId": "d3b26cf9-6d9f-448f-f8c1-ac01a7d9b106"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.7.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.25.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.1.1)\n",
            "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cpu)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install spacy nltk\n",
        "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yq8RTvv7BF3",
        "outputId": "f62f2abd-86bc-4f81-ef93-4fece8cfdaf8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'intents': [{'tag': 'greeting',\n",
              "   'patterns': ['Hi',\n",
              "    'Hey',\n",
              "    'How are you',\n",
              "    'Is anyone there?',\n",
              "    'Hello',\n",
              "    'Good day'],\n",
              "   'responses': ['Hey :-)',\n",
              "    'Hello, thanks for visiting',\n",
              "    'Hi there, what can I do for you?',\n",
              "    'Hi there, how can I help?']},\n",
              "  {'tag': 'goodbye',\n",
              "   'patterns': ['Bye', 'See you later', 'Goodbye'],\n",
              "   'responses': ['See you later, thanks for visiting',\n",
              "    'Have a nice day',\n",
              "    'Bye! Come back again soon.']},\n",
              "  {'tag': 'thanks',\n",
              "   'patterns': ['Thanks', 'Thank you', \"That's helpful\", \"Thank's a lot!\"],\n",
              "   'responses': ['Happy to help!', 'Any time!', 'My pleasure']},\n",
              "  {'tag': 'items',\n",
              "   'patterns': ['tell me about this app',\n",
              "    'What kinds of technology used?',\n",
              "    'What do you have?'],\n",
              "   'responses': ['Write something about the app.']},\n",
              "  {'tag': 'funny',\n",
              "   'patterns': ['Tell me a joke!',\n",
              "    'Tell me something funny!',\n",
              "    'Do you know a joke?'],\n",
              "   'responses': ['Why did the hipster burn his mouth? He drank the coffee before it was cool.',\n",
              "    'What did the buffalo say when his son left for college? Bison.']}]}"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "{\n",
        "  \"intents\": [\n",
        "    {\n",
        "      \"tag\": \"greeting\",\n",
        "      \"patterns\": [\n",
        "        \"Hi\",\n",
        "        \"Hey\",\n",
        "        \"How are you\",\n",
        "        \"Is anyone there?\",\n",
        "        \"Hello\",\n",
        "        \"Good day\"\n",
        "      ],\n",
        "      \"responses\": [\n",
        "        \"Hey :-)\",\n",
        "        \"Hello, thanks for visiting\",\n",
        "        \"Hi there, what can I do for you?\",\n",
        "        \"Hi there, how can I help?\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"goodbye\",\n",
        "      \"patterns\": [\"Bye\", \"See you later\", \"Goodbye\"],\n",
        "      \"responses\": [\n",
        "        \"See you later, thanks for visiting\",\n",
        "        \"Have a nice day\",\n",
        "        \"Bye! Come back again soon.\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"thanks\",\n",
        "      \"patterns\": [\"Thanks\", \"Thank you\", \"That's helpful\", \"Thank's a lot!\"],\n",
        "      \"responses\": [\"Happy to help!\", \"Any time!\", \"My pleasure\"]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"items\",\n",
        "      \"patterns\": [\n",
        "        \"tell me about this app\",\n",
        "        \"What kinds of technology used?\",\n",
        "        \"What do you have?\"\n",
        "      ],\n",
        "      \"responses\": [\n",
        "        \"Write something about the app.\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"funny\",\n",
        "      \"patterns\": [\n",
        "        \"Tell me a joke!\",\n",
        "        \"Tell me something funny!\",\n",
        "        \"Do you know a joke?\"\n",
        "      ],\n",
        "      \"responses\": [\n",
        "        \"Why did the hipster burn his mouth? He drank the coffee before it was cool.\",\n",
        "        \"What did the buffalo say when his son left for college? Bison.\"\n",
        "      ]\n",
        "    }\n",
        "  ]\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GhVMvKI7KPb"
      },
      "outputs": [],
      "source": [
        "#model.py file\n",
        "import torch.nn as nn\n",
        "\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.l1 = nn.Linear(input_size, hidden_size)\n",
        "        self.l2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.l3 = nn.Linear(hidden_size, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.l1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.l2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.l3(out)\n",
        "        # no activation and no softmax at the end\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bsWZkOuD7Tih"
      },
      "outputs": [],
      "source": [
        "#nltk_utils.py\n",
        "#nltk library used for building Python programs that work with human language data for applying in\n",
        "#statistical natural language processing (NLP)\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def tokenize(sentence):\n",
        "    \"\"\"\n",
        "    split sentence into array of words/tokens\n",
        "    a token can be a word or punctuation character, or number\n",
        "    \"\"\"\n",
        "    return nltk.word_tokenize(sentence)\n",
        "\n",
        "\n",
        "def stem(word):\n",
        "    \"\"\"\n",
        "    stemming = find the root form of the word\n",
        "    examples:\n",
        "    words = [\"organize\", \"organizes\", \"organizing\"]\n",
        "    words = [stem(w) for w in words]\n",
        "    -> [\"organ\", \"organ\", \"organ\"]\n",
        "    \"\"\"\n",
        "    return stemmer.stem(word.lower())\n",
        "\n",
        "\n",
        "def bag_of_words(tokenized_sentence, words):\n",
        "    \"\"\"\n",
        "    return bag of words array:\n",
        "    1 for each known word that exists in the sentence, 0 otherwise\n",
        "    example:\n",
        "    sentence = [\"hello\", \"how\", \"are\", \"you\"]\n",
        "    words = [\"hi\", \"hello\", \"I\", \"you\", \"bye\", \"thank\", \"cool\"]\n",
        "    bog   = [  0 ,    1 ,    0 ,   1 ,    0 ,    0 ,      0]\n",
        "    \"\"\"\n",
        "    # stem each word\n",
        "    sentence_words = [stem(word) for word in tokenized_sentence]\n",
        "    # initialize bag with 0 for each word\n",
        "    bag = np.zeros(len(words), dtype=np.float32)\n",
        "    for idx, w in enumerate(words):\n",
        "        if w in sentence_words:\n",
        "            bag[idx] = 1\n",
        "    return bag\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l17JR33X92Pb"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"/path/to/nltk_utils\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sq3xFNvL9gBV",
        "outputId": "5ac4eed8-3247-4714-cd3c-1acd3646de0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "232 patterns\n",
            "80 tags: ['about', 'afternoon', 'anxious', 'ask', 'casual', 'creation', 'death', 'default', 'depressed', 'done', 'evening', 'fact-1', 'fact-10', 'fact-11', 'fact-12', 'fact-13', 'fact-14', 'fact-15', 'fact-16', 'fact-17', 'fact-18', 'fact-19', 'fact-2', 'fact-20', 'fact-21', 'fact-22', 'fact-23', 'fact-24', 'fact-25', 'fact-26', 'fact-27', 'fact-28', 'fact-29', 'fact-3', 'fact-30', 'fact-31', 'fact-32', 'fact-5', 'fact-6', 'fact-7', 'fact-8', 'fact-9', 'friends', 'goodbye', 'greeting', 'happy', 'hate-me', 'hate-you', 'help', 'jokes', 'learn-mental-health', 'learn-more', 'location', 'meditation', 'mental-health-fact', 'morning', 'name', 'neutral-response', 'night', 'no-approach', 'no-response', 'not-talking', 'pandora-useful', 'problem', 'repeat', 'sad', 'scared', 'skill', 'sleep', 'something-else', 'stressed', 'stupid', 'suicide', 'thanks', 'understand', 'user-advice', 'user-agree', 'user-meditation', 'worthless', 'wrong']\n",
            "280 unique stemmed words: [\"'ll\", \"'m\", \"'re\", \"'s\", \"'ve\", ',', 'a', 'about', 'absolut', 'advic', 'affect', 'afternoon', 'again', 'all', 'alot', 'alreadi', 'am', 'and', 'ani', 'anoth', 'answer', 'anxieti', 'anxiou', 'anymor', 'anyon', 'anyth', 'appear', 'approach', 'are', 'ask', 'au', 'avail', 'aw', 'away', 'be', 'becaus', 'becom', 'befor', 'better', 'between', 'bonjour', 'boyfriend', 'break', 'bring', 'brother', 'burn', 'by', 'bye', 'ca', 'call', 'can', 'caus', 'cheer', 'child', 'commit', 'connect', 'continu', 'control', 'could', 'crazi', 'creat', 'cure', 'dad', 'day', 'defin', 'depress', 'deserv', 'did', 'die', 'differ', 'disord', 'do', 'doe', 'down', 'dumb', 'els', 'empti', 'enough', 'even', 'exam', 'fact', 'famili', 'fare', 'feel', 'few', 'financi', 'find', 'fine', 'focu', 'for', 'friend', 'from', 'get', 'girlfriend', 'give', 'go', 'good', 'goodby', 'great', 'group', 'guess', 'guten', 'had', 'hand', 'happi', 'hate', 'have', 'health', 'hello', 'help', 'hey', 'hi', 'hmmm', 'hola', 'how', 'howdi', 'i', 'if', 'ill', 'import', 'in', 'insominia', 'insomnia', 'interest', 'involv', 'is', 'it', 'joke', 'just', 'k', 'kill', 'know', 'konnichiwa', 'last', 'later', 'learn', 'let', 'like', 'live', 'locat', 'lone', 'made', 'maintain', 'make', 'me', 'mean', 'medic', 'medit', 'mental', 'mention', 'mom', 'money', 'more', 'morn', 'much', 'my', 'myself', \"n't\", 'name', 'need', 'new', 'nice', 'night', 'no', 'nobodi', 'not', 'noth', 'now', 'of', 'oh', 'ok', 'okay', 'ola', 'on', 'one', 'open', 'option', 'or', 'out', 'pass', 'past', 'peopl', 'pleas', 'possibl', 'practic', 'prepar', 'prevent', 'probabl', 'problem', 'profession', 'proper', 'realli', 'recov', 'relationship', 'repeat', 'respons', 'revoir', 'right', 'robot', 'sad', 'said', 'say', 'sayonara', 'scare', 'see', 'seem', 'sens', 'should', 'shut', 'sign', 'sister', 'sleep', 'slept', 'so', 'social', 'some', 'someon', 'someth', 'sound', 'start', 'stay', 'still', 'stress', 'stuck', 'stupid', 'suffer', 'suicid', 'support', 'sure', 'symptom', 'tag', 'take', 'talk', 'tell', 'than', 'thank', 'that', 'the', 'thee', 'then', 'therapi', 'therapist', 'there', 'thi', 'think', 'thought', 'through', 'to', 'today', 'told', 'treatment', 'trust', 'type', 'understand', 'unwel', 'up', 'use', 'useless', 'veri', 'want', 'warn', 'way', 'we', 'well', 'were', 'what', 'whatev', 'where', 'whi', 'who', 'with', 'worri', 'worthless', 'would', 'wrong', 'ye', 'yeah', 'you', 'your', 'yourself']\n",
            "280 80\n",
            "Epoch [100/1000], Loss: 0.4356\n",
            "Epoch [200/1000], Loss: 0.0514\n",
            "Epoch [300/1000], Loss: 0.0081\n",
            "Epoch [400/1000], Loss: 0.0006\n",
            "Epoch [500/1000], Loss: 0.0002\n",
            "Epoch [600/1000], Loss: 0.0000\n",
            "Epoch [700/1000], Loss: 0.0000\n",
            "Epoch [800/1000], Loss: 0.0000\n",
            "Epoch [900/1000], Loss: 0.0000\n",
            "Epoch [1000/1000], Loss: 0.0000\n",
            "final loss: 0.0000\n",
            "training complete. file saved to chatdata.pth\n"
          ]
        }
      ],
      "source": [
        "#train.py\n",
        "import numpy as np\n",
        "import json,torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "with open('/content/intents.json', 'r') as f:\n",
        "    intents = json.load(f)\n",
        "\n",
        "all_words = []\n",
        "tags = []\n",
        "xy = []\n",
        "# loop through each sentence in our intents patterns\n",
        "for intent in intents['intents']:\n",
        "    tag = intent['tag']\n",
        "    # add to tag list\n",
        "    tags.append(tag)\n",
        "    for pattern in intent['patterns']:\n",
        "        # tokenize each word in the sentence\n",
        "        w = tokenize(pattern)\n",
        "        # add to our words list\n",
        "        all_words.extend(w)\n",
        "        # add to xy pair\n",
        "        xy.append((w, tag))\n",
        "\n",
        "# stem and lower each word\n",
        "ignore_words = ['?', '.', '!']\n",
        "all_words = [stem(w) for w in all_words if w not in ignore_words]\n",
        "# remove duplicates and sort\n",
        "all_words = sorted(set(all_words))\n",
        "tags = sorted(set(tags))\n",
        "\n",
        "print(len(xy), \"patterns\")\n",
        "print(len(tags), \"tags:\", tags)\n",
        "print(len(all_words), \"unique stemmed words:\", all_words)\n",
        "\n",
        "# create training data\n",
        "X_train = []\n",
        "y_train = []\n",
        "for (pattern_sentence, tag) in xy:\n",
        "    # X: bag of words for each pattern_sentence\n",
        "    bag = bag_of_words(pattern_sentence, all_words)\n",
        "    X_train.append(bag)\n",
        "    # y: PyTorch CrossEntropyLoss needs only class labels, not one-hot\n",
        "    label = tags.index(tag)\n",
        "    y_train.append(label)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "# Hyper-parameters\n",
        "num_epochs = 1000\n",
        "batch_size = 8\n",
        "learning_rate = 0.001\n",
        "input_size = len(X_train[0])\n",
        "hidden_size = 8\n",
        "output_size = len(tags)\n",
        "print(input_size, output_size)\n",
        "\n",
        "class ChatDataset(Dataset):\n",
        "    def __init__(self):\n",
        "        self.n_samples = len(X_train)\n",
        "        self.x_data = X_train\n",
        "        self.y_data = y_train\n",
        "\n",
        "    # support indexing such that dataset[i] can be used to get i-th sample\n",
        "    def __getitem__(self, index):\n",
        "        return self.x_data[index], self.y_data[index]\n",
        "\n",
        "    # we can call len(dataset) to return the size\n",
        "    def __len__(self):\n",
        "        return self.n_samples\n",
        "\n",
        "dataset = ChatDataset()\n",
        "train_loader = DataLoader(dataset=dataset,\n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=True,\n",
        "                          num_workers=0)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = NeuralNet(input_size, hidden_size, output_size).to(device)\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "    for (words, labels) in train_loader:\n",
        "        words = words.to(device)\n",
        "        labels = labels.to(dtype=torch.long).to(device)\n",
        "        # Forward pass\n",
        "        outputs = model(words)\n",
        "        # if y would be one-hot, we must apply\n",
        "        # labels = torch.max(labels, 1)[1]\n",
        "        loss = criterion(outputs, labels)\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    if (epoch+1) % 100 == 0:\n",
        "        print (f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "print(f'final loss: {loss.item():.4f}')\n",
        "data = {\n",
        "\"model_state\": model.state_dict(),\n",
        "\"input_size\": input_size,\n",
        "\"hidden_size\": hidden_size,\n",
        "\"output_size\": output_size,\n",
        "\"all_words\": all_words,\n",
        "\"tags\": tags\n",
        "}\n",
        "FILE = \"chatdata.pth\"\n",
        "torch.save(data, FILE)\n",
        "print(f'training complete. file saved to {FILE}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2wFvjp68F4S",
        "outputId": "c676dd78-01df-4c57-beaf-9541c8fdd9a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Let's chat! (type 'quit' to exit)\n",
            "Hi there. How are you feeling today?\n",
            "Can you elaborate on that?\n",
            "I'm here for you. Could you tell me why you're feeling this way?\n",
            "Oh nice to meet you. Tell me how was your week?\n",
            "That's a great name. Tell me more about yourself.\n",
            "I do not understand...\n",
            "It's only natural to feel this way. Tell me more. What else is on your mind?\n",
            "I do not understand...\n",
            "What do you think is the reason behind this?\n",
            "I do not understand...\n",
            "Not sure I understand that.\n",
            "Call me Pandora\n",
            "Sorry, I didn't understand you.\n",
            "Please go on.\n",
            "I'll see you soon.\n",
            "Hello there. Glad to see you're back. What's going on in your world right now?\n"
          ]
        }
      ],
      "source": [
        "#chat.py\n",
        "import os,random,json,torch\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "with open(\"/content/intents.json\") as json_data:\n",
        "    intents = json.load(json_data)\n",
        "\n",
        "FILE = os.path.join('/content/chatdata.pth')\n",
        "data = torch.load(FILE)\n",
        "\n",
        "input_size = data[\"input_size\"]\n",
        "hidden_size = data[\"hidden_size\"]\n",
        "output_size = data[\"output_size\"]\n",
        "all_words = data['all_words']\n",
        "tags = data['tags']\n",
        "model_state = data[\"model_state\"]\n",
        "\n",
        "model = NeuralNet(input_size, hidden_size, output_size).to(device)\n",
        "model.load_state_dict(model_state)\n",
        "model.eval()\n",
        "\n",
        "bot_name = \"iris-NLP\"\n",
        "def get_response(msg):\n",
        "    sentence = tokenize(msg)\n",
        "    X = bag_of_words(sentence, all_words)\n",
        "    X = X.reshape(1, X.shape[0])\n",
        "    X = torch.from_numpy(X).to(device)\n",
        "\n",
        "    output = model(X)\n",
        "    _, predicted = torch.max(output, dim=1)\n",
        "\n",
        "    tag = tags[predicted.item()]\n",
        "\n",
        "    probs = torch.softmax(output, dim=1)\n",
        "    prob = probs[0][predicted.item()]\n",
        "    if prob.item() > 0.75:\n",
        "        for intent in intents['intents']:\n",
        "            if tag == intent[\"tag\"]:\n",
        "                return random.choice(intent['responses'])\n",
        "    return \"I do not understand...\"\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Let's chat! (type 'quit' to exit)\")\n",
        "    while True:\n",
        "        sentence = input(\"You: \")\n",
        "        if sentence == \"quit\":\n",
        "            break\n",
        "        resp = get_response(sentence)\n",
        "        print(resp)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldocxaoo9M17"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOhkWl8gkoNWgv6xV9W8xAM",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}